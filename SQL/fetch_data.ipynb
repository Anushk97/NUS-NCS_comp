{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "AccountKey=\"\"\n",
    "\n",
    "datasets = {'bus_routes': \"http://datamall2.mytransport.sg/ltaodataservice/BusRoutes\",\n",
    "            'bus_services': \"http://datamall2.mytransport.sg/ltaodataservice/BusServices\",\n",
    "            'bus_stops': \"http://datamall2.mytransport.sg/ltaodataservice/BusStops\",\n",
    "            'bus_arrival': \"http://datamall2.mytransport.sg/ltaodataservice/BusArrivalv2\",\n",
    "            'taxi_availability': \"http://datamall2.mytransport.sg/ltaodataservice/Taxi-Availability\",\n",
    "            'taxi_stands': \"http://datamall2.mytransport.sg/ltaodataservice/TaxiStands\",\n",
    "            'train_service_alers': \"http://datamall2.mytransport.sg/ltaodataservice/TrainServiceAlerts\",\n",
    "            'carpark_availability': \"http://datamall2.mytransport.sg/ltaodataservice/CarParkAvailabilityv2\",\n",
    "            'erp_rates': \"http://datamall2.mytransport.sg/ltaodataservice/ERPRates\",\n",
    "            'est_travel_times': \"http://datamall2.mytransport.sg/ltaodataservice/EstTravelTimes\",\n",
    "            'faulty_traffic_lights': \"http://datamall2.mytransport.sg/ltaodataservice/FaultyTrafficLights\",\n",
    "            'road_openings': \"http://datamall2.mytransport.sg/ltaodataservice/RoadOpenings\", \n",
    "            'road_works': \"http://datamall2.mytransport.sg/ltaodataservice/RoadWorks\", \n",
    "            'traffic_images': \"http://datamall2.mytransport.sg/ltaodataservice/Traffic-Imagesv2\",\n",
    "            'traffic_incidents': \"http://datamall2.mytransport.sg/ltaodataservice/TrafficIncidents\",\n",
    "            'traffic_speed_bands': \"http://datamall2.mytransport.sg/ltaodataservice/v3/TrafficSpeedBands\",\n",
    "            'vms_emas': \"http://datamall2.mytransport.sg/ltaodataservice/VMS\",\n",
    "            'bicycle_parking': \"http://datamall2.mytransport.sg/ltaodataservice/BicycleParkingv2\",\n",
    "            'platform_crowd_density': \"http://datamall2.mytransport.sg/ltaodataservice/PCDRealTime\",\n",
    "            'platform_crowd_density_forecase': \"http://datamall2.mytransport.sg/ltaodataservice/PCDForecast\", \n",
    "            'traffic_flow': \"http://datamall2.mytransport.sg/ltaodataservice/TrafficFlow\",\n",
    "            'facilities_maintanance': \"http://datamall2.mytransport.sg/ltaodataservice/FacilitiesMaintenance\",\n",
    "            'geospatial_island_map': \"http://datamall2.mytransport.sg/ltaodataservice/GeospatialWholeIslan\", \n",
    "            'passenger_vol_by_train_station': \"http://datamall2.mytransport.sg/ltaodataservice/PV/Train\",\n",
    "            'passenger_vol_by_origin_train_station': \"http://datamall2.mytransport.sg/ltaodataservice/PV/ODTrain\",\n",
    "            'passenger_vol_by_origin_bus_stop': \"http://datamall2.mytransport.sg/ltaodataservice/PV/ODBus\",\n",
    "            'passenger_vol_by_bus_stop': \"http://datamall2.mytransport.sg/ltaodataservice/PV/Bus\",\n",
    "            \n",
    "            'faulty_traffic_lights': \"http://datamall2.mytransport.sg/ltaodataservice/FaultyTrafficLights\",\n",
    "            'traffic_incidents': \"http://datamall2.mytransport.sg/ltaodataservice/TrafficIncidents\",\n",
    "            'road_openings': \"http://datamall2.mytransport.sg/ltaodataservice/RoadOpenings\", \n",
    "            'road_works': \"http://datamall2.mytransport.sg/ltaodataservice/RoadWorks\",\n",
    "            'traffic_flow': \"http://datamall2.mytransport.sg/ltaodataservice/TrafficFlow\", \n",
    "            'estimated_travel_times': \"http://datamall2.mytransport.sg/ltaodataservice/EstTravelTimes\",\n",
    "            'carpark_avail': \"http://datamall2.mytransport.sg/ltaodataservice/CarParkAvailabilityv2\",\n",
    "            'traffic_flow': \"http://datamall2.mytransport.sg/ltaodataservice/TrafficFlow\"\n",
    "            }\n",
    "\n",
    "payload = {}\n",
    "\n",
    "# API key\n",
    "headers = {\n",
    "  'AccountKey': AccountKey\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_link = \"traffic_flow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "#This makes calls to all datasets\n",
    "def obtain_data(data_source_name):\n",
    "    df = {}\n",
    "    for i, v in datasets.items():\n",
    "        response = requests.request(\"GET\", v, headers=headers, data=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            if 'value' in data:\n",
    "                df[i] = pd.DataFrame(data['value'])\n",
    "\n",
    "    return df[data_source_name]\n",
    "\n",
    "#this makes call to one dataset at a time\n",
    "def obtain_data_per_dataset(data_source_name):\n",
    "    response = requests.get(datasets[data_source_name], headers=headers,data=payload)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'value' in data:\n",
    "            df = pd.DataFrame(data['value'])\n",
    "            return df\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "def append_new_data(source_path, source_filename, curr_df, drop_dup_by_fields, printout=False):\n",
    "    # If the source directory doesn't exist, create it\n",
    "    if not os.path.exists(source_path):\n",
    "        os.makedirs(source_path)\n",
    "\n",
    "    source_file_path = os.path.join(source_path, source_filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(source_file_path):\n",
    "        try:\n",
    "            source_df = pd.read_csv(source_file_path)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: {source_file_path} is empty.\")\n",
    "            source_df = pd.DataFrame()  \n",
    "    else:\n",
    "        source_df = pd.DataFrame()\n",
    "        print(f\"No existing data found, creating a new data file.\")\n",
    "\n",
    "    # Identify new data\n",
    "    if not source_df.empty:\n",
    "        if len(drop_dup_by_fields) > 0:\n",
    "            df = pd.concat([curr_df, source_df], ignore_index=True).drop_duplicates(subset=drop_dup_by_fields)\n",
    "        else:\n",
    "            df = pd.concat([curr_df, source_df], ignore_index=True).drop_duplicates()\n",
    "    else:\n",
    "        df = curr_df \n",
    "        \n",
    "    df.to_csv(source_file_path, index=False)\n",
    "    msg = f\"Saved {len(df)} records to path: {source_file_path}\"\n",
    "    if printout: print(msg)\n",
    "    \n",
    "    \n",
    "def obtain_and_append(api_file_name, save_data_to, source_file_name, drop_dup_by_fields, printout):\n",
    "    \n",
    "    if api_file_name == \"traffic_incidents\":\n",
    "        #df = obtain_data(api_file_name)\n",
    "        df = obtain_data_per_dataset(api_file_name) #changed the function here to newer version\n",
    "        df['Date_time'] = df['Message'].apply(lambda x: format_datetime(x))\n",
    "    if api_file_name == 'traffic_flow':\n",
    "        df = obtain_data_from_link(dataset_with_link) #added this if dataset has a link\n",
    "    else:\n",
    "        df = obtain_data(api_file_name)\n",
    "        \n",
    "    append_new_data(\n",
    "        source_path=save_data_to, \n",
    "        source_filename=source_file_name, \n",
    "        curr_df=df,\n",
    "        drop_dup_by_fields = drop_dup_by_fields,\n",
    "        printout = printout\n",
    "    )\n",
    "\n",
    "def format_datetime(datetime_str):\n",
    "    match = re.search(r'\\((\\d{1,2}/\\d{1,2})\\)(\\d{1,2}:\\d{2})', datetime_str)\n",
    "    if match:\n",
    "        extracted_date = match.group(1)\n",
    "        extracted_time = match.group(2)\n",
    "        current_year = datetime.now().year\n",
    "        extracted_date_parts = extracted_date.split('/')\n",
    "        formatted_date = f\"{current_year}-{extracted_date_parts[1].zfill(2)}-{extracted_date_parts[0].zfill(2)}\"\n",
    "        formatted_datetime = f\"{formatted_date}-{extracted_time}\"\n",
    "        return formatted_datetime\n",
    "    else:\n",
    "        return datetime_str\n",
    "\n",
    "\n",
    "def obtain_data_from_link(dataset_with_link):\n",
    "    link = obtain_data_per_dataset(dataset_with_link)  # Make sure obtain_data() returns the correct information\n",
    "    access_here = link['Link'].iloc[0]\n",
    "    print(access_here)\n",
    "\n",
    "    with urllib.request.urlopen(access_here) as response:\n",
    "        contents = response.read()\n",
    "        try:\n",
    "            text = contents.decode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            \n",
    "            text = contents.decode('iso-8859-1')\n",
    "        \n",
    "        json_data = json.loads(text)\n",
    "\n",
    "    if 'Value' in json_data:\n",
    "        df = pd.DataFrame(json_data['Value'])\n",
    "        return df\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "def generate_create_table_statement(df, table_name):\n",
    "    sql = f\"CREATE TABLE {table_name} (\\n\"\n",
    "    \n",
    "    column_definitions = []\n",
    "    for column, dtype in df.dtypes.items():\n",
    "        column_type = 'varchar(255)' \n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            column_type = 'int'\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            column_type = 'real'\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            column_type = 'datetime'\n",
    "        elif pd.api.types.is_string_dtype(dtype):\n",
    "            column_type = 'varchar(255)'\n",
    "        \n",
    "        column_definitions.append(f\"    {column} {column_type}\")\n",
    "    \n",
    "    sql += \",\\n\".join(column_definitions)\n",
    "    sql += \"\\n);\"\n",
    "    \n",
    "    return sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 121 records to path: ./Data/traffic_incidents\\traffic_incidents.csv\n",
      "Warning: ./Data/faulty_traffic_lights\\faulty_traffic_lights.csv is empty.\n",
      "Saved 0 records to path: ./Data/faulty_traffic_lights\\faulty_traffic_lights.csv\n",
      "Saved 8 records to path: ./Data/road_openings\\road_openings.csv\n",
      "Saved 233 records to path: ./Data/road_works\\road_works.csv\n",
      "Saved 200 records to path: ./Data/estimated_travel_times\\estimated_travel_times.csv\n",
      "Saved 411 records to path: ./Data/carpark_avail\\carpark_avail.csv\n",
      "Saved 984 records to path: ./Data/bus_routes\\bus_routes.csv\n",
      "Saved 1000 records to path: ./Data/bus_stops\\bus_stops.csv\n",
      "Saved 2438 records to path: ./Data/taxi_availability\\taxi_availability.csv\n",
      "Saved 1000 records to path: ./Data/traffic_speed_bands\\traffic_speed_bands.csv\n",
      "\n",
      "\n",
      "Saved 121 records to path: ./Data/traffic_incidents\\traffic_incidents.csv\n",
      "Warning: ./Data/faulty_traffic_lights\\faulty_traffic_lights.csv is empty.\n",
      "Saved 0 records to path: ./Data/faulty_traffic_lights\\faulty_traffic_lights.csv\n",
      "Saved 8 records to path: ./Data/road_openings\\road_openings.csv\n",
      "Saved 233 records to path: ./Data/road_works\\road_works.csv\n",
      "Saved 200 records to path: ./Data/estimated_travel_times\\estimated_travel_times.csv\n",
      "Saved 411 records to path: ./Data/carpark_avail\\carpark_avail.csv\n",
      "Saved 984 records to path: ./Data/bus_routes\\bus_routes.csv\n",
      "Saved 1000 records to path: ./Data/bus_stops\\bus_stops.csv\n",
      "Saved 2918 records to path: ./Data/taxi_availability\\taxi_availability.csv\n",
      "Saved 1000 records to path: ./Data/traffic_speed_bands\\traffic_speed_bands.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 10000:    \n",
    "    obtain_and_append(\n",
    "        api_file_name = \"traffic_incidents\", \n",
    "        save_data_to = \"./Data/traffic_incidents\", \n",
    "        source_file_name = \"traffic_incidents.csv\", \n",
    "        drop_dup_by_fields = [\"Message\"],\n",
    "        printout=True\n",
    "    )\n",
    "    \n",
    "    obtain_and_append(\n",
    "        api_file_name = \"faulty_traffic_lights\", \n",
    "        save_data_to = \"./Data/faulty_traffic_lights\", \n",
    "        source_file_name = \"faulty_traffic_lights.csv\", \n",
    "        drop_dup_by_fields = [\"AlarmID\", \"NodeID\"],\n",
    "        printout=True\n",
    "    )\n",
    "        \n",
    "    obtain_and_append(\n",
    "        api_file_name = \"road_openings\", \n",
    "        save_data_to = \"./Data/road_openings\", \n",
    "        source_file_name = \"road_openings.csv\", \n",
    "        drop_dup_by_fields = [\"EventID\"],\n",
    "        printout=True\n",
    "    )\n",
    "        \n",
    "    obtain_and_append(\n",
    "        api_file_name = \"road_works\", \n",
    "        save_data_to = \"./Data/road_works\", \n",
    "        source_file_name = \"road_works.csv\", \n",
    "        drop_dup_by_fields = [\"EventID\"],\n",
    "        printout=True\n",
    "    )\n",
    "        \n",
    "    obtain_and_append(\n",
    "        api_file_name = \"estimated_travel_times\", \n",
    "        save_data_to = \"./Data/estimated_travel_times\", \n",
    "        source_file_name = \"estimated_travel_times.csv\", \n",
    "        drop_dup_by_fields = [\"Name\", \"Direction\", \"FarEndPoint\", \"StartPoint\", \"EndPoint\", \"EstTime\"],\n",
    "        printout=True\n",
    "    )\n",
    "        \n",
    "    obtain_and_append(\n",
    "        api_file_name = \"carpark_avail\", \n",
    "        save_data_to = \"./Data/carpark_avail\", \n",
    "        source_file_name = \"carpark_avail.csv\", \n",
    "        drop_dup_by_fields = ['CarParkID'],\n",
    "        printout=True\n",
    "    )\n",
    "\n",
    "    obtain_and_append(\n",
    "        api_file_name = \"bus_routes\", \n",
    "        save_data_to = \"./Data/bus_routes\", \n",
    "        source_file_name = \"bus_routes.csv\", \n",
    "        drop_dup_by_fields = ['ServiceNo', 'BusStopCode'],\n",
    "        printout=True\n",
    "    )\n",
    "\n",
    "    obtain_and_append(\n",
    "        api_file_name = \"bus_stops\", \n",
    "        save_data_to = \"./Data/bus_stops\", \n",
    "        source_file_name = \"bus_stops.csv\", \n",
    "        drop_dup_by_fields = ['BusStopCode'],\n",
    "        printout=True\n",
    "    )\n",
    "\n",
    "    obtain_and_append(\n",
    "        api_file_name = \"taxi_availability\", \n",
    "        save_data_to = \"./Data/taxi_availability\", \n",
    "        source_file_name = \"taxi_availability.csv\", \n",
    "        drop_dup_by_fields = [],\n",
    "        printout=True\n",
    "    )\n",
    "    \n",
    "    # obtain_and_append(\n",
    "    #     api_file_name = \"taxi_stands\", \n",
    "    #     save_data_to = \"./Data/taxi_stands\", \n",
    "    #     source_file_name = \"taxi_stands.csv\", \n",
    "    #     drop_dup_by_fields = [],\n",
    "    #     printout=True\n",
    "    # )\n",
    "\n",
    "    obtain_and_append(\n",
    "        api_file_name = \"traffic_speed_bands\", \n",
    "        save_data_to = \"./Data/traffic_speed_bands\", \n",
    "        source_file_name = \"traffic_speed_bands.csv\", \n",
    "        drop_dup_by_fields = ['LinkID'],\n",
    "        printout=True\n",
    "    )\n",
    "\n",
    "    # obtain_and_append(\n",
    "    #     api_file_name = \"traffic_flow\", \n",
    "    #     save_data_to = \"/Users/emmy/Desktop/Last_term_SMU/NUS_proj/nus_comp/data\", \n",
    "    #     source_file_name = \"traffic_flow.csv\", \n",
    "    #     drop_dup_by_fields = None,\n",
    "    #     printout=True\n",
    "    # )\n",
    "    \n",
    "        \n",
    "    print(\"\\n\")\n",
    "    i += 1\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>DayType</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>ZoneID</th>\n",
       "      <th>ChargeAmount</th>\n",
       "      <th>EffectiveDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger Cars/Light Goods Vehicles/Taxis</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>07:00</td>\n",
       "      <td>08:00</td>\n",
       "      <td>AY1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Passenger Cars/Light Goods Vehicles/Taxis</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>08:00</td>\n",
       "      <td>08:05</td>\n",
       "      <td>AY1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passenger Cars/Light Goods Vehicles/Taxis</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>08:05</td>\n",
       "      <td>08:30</td>\n",
       "      <td>AY1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passenger Cars/Light Goods Vehicles/Taxis</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>08:30</td>\n",
       "      <td>08:35</td>\n",
       "      <td>AY1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Passenger Cars/Light Goods Vehicles/Taxis</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>08:35</td>\n",
       "      <td>08:55</td>\n",
       "      <td>AY1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Light Goods Vehicles</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>17:30</td>\n",
       "      <td>18:00</td>\n",
       "      <td>CBD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Light Goods Vehicles</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>18:00</td>\n",
       "      <td>18:05</td>\n",
       "      <td>CBD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Light Goods Vehicles</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>18:05</td>\n",
       "      <td>18:25</td>\n",
       "      <td>CBD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Light Goods Vehicles</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>18:25</td>\n",
       "      <td>18:30</td>\n",
       "      <td>CBD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Light Goods Vehicles</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>18:30</td>\n",
       "      <td>18:55</td>\n",
       "      <td>CBD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   VehicleType   DayType StartTime EndTime  \\\n",
       "0    Passenger Cars/Light Goods Vehicles/Taxis  Weekdays     07:00   08:00   \n",
       "1    Passenger Cars/Light Goods Vehicles/Taxis  Weekdays     08:00   08:05   \n",
       "2    Passenger Cars/Light Goods Vehicles/Taxis  Weekdays     08:05   08:30   \n",
       "3    Passenger Cars/Light Goods Vehicles/Taxis  Weekdays     08:30   08:35   \n",
       "4    Passenger Cars/Light Goods Vehicles/Taxis  Weekdays     08:35   08:55   \n",
       "..                                         ...       ...       ...     ...   \n",
       "495                       Light Goods Vehicles  Weekdays     17:30   18:00   \n",
       "496                       Light Goods Vehicles  Weekdays     18:00   18:05   \n",
       "497                       Light Goods Vehicles  Weekdays     18:05   18:25   \n",
       "498                       Light Goods Vehicles  Weekdays     18:25   18:30   \n",
       "499                       Light Goods Vehicles  Weekdays     18:30   18:55   \n",
       "\n",
       "    ZoneID  ChargeAmount EffectiveDate  \n",
       "0      AY1           0.0    2024-01-02  \n",
       "1      AY1           0.5    2024-01-02  \n",
       "2      AY1           1.0    2024-01-02  \n",
       "3      AY1           1.5    2024-01-02  \n",
       "4      AY1           2.0    2024-01-02  \n",
       "..     ...           ...           ...  \n",
       "495    CBD           0.0    2024-01-02  \n",
       "496    CBD           0.0    2024-01-02  \n",
       "497    CBD           0.0    2024-01-02  \n",
       "498    CBD           0.0    2024-01-02  \n",
       "499    CBD           0.0    2024-01-02  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_link = \"erp_rates\"\n",
    "tmp_df = obtain_data_per_dataset(dataset_with_link)\n",
    "tmp_df\n",
    "\n",
    "#df_with_link = obtain_data_from_link(dataset_with_link)\n",
    "#df_with_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE traffic_flow (\n",
      "    LinkID varchar(255),\n",
      "    Date varchar(255),\n",
      "    HourOfDate varchar(255),\n",
      "    Volume varchar(255),\n",
      "    StartLon varchar(255),\n",
      "    StartLat varchar(255),\n",
      "    EndLon varchar(255),\n",
      "    EndLat varchar(255),\n",
      "    RoadName varchar(255),\n",
      "    RoadCat varchar(255)\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "print(generate_create_table_statement(tmp_df, dataset_with_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
